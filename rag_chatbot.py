import os
import json
from typing import List, Dict, Optional, Union, Any, Tuple
from pathlib import Path
import logging
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter

# LangChain importlarÄ±
from langchain_core.documents import Document
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma, FAISS
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_openai import ChatOpenAI

class RAGChatbot:
    def __init__(
        self,
        vector_store_path: str = "./vector_store",
        embedding_model: str = "text-embedding-3-small",  # OpenAI varsayÄ±lan embedding modeli
        vector_db_type: str = "chroma",
        max_context_length: int = 4096,  # GPT-4o iÃ§in daha uzun baÄŸlam
        max_history_length: int = 10,  # Daha uzun sohbet geÃ§miÅŸi
        openai_model: str = "gpt-4o",  # OpenAI model seÃ§eneÄŸi
        temperature: float = 0.7,  # SÄ±caklÄ±k parametresi
        collection_name: str = "women_rights",  # VektÃ¶r veritabanÄ± koleksiyon adÄ±
        diversity_factor: float = 0.3  # YanÄ±t Ã§eÅŸitliliÄŸi faktÃ¶rÃ¼ (0-1 arasÄ±)
    ):
        # .env dosyasÄ±ndan API anahtarÄ±nÄ± yÃ¼kle
        load_dotenv()
        
        self.vector_store_path = Path(vector_store_path)
        self.vector_db_type = vector_db_type
        self.max_context_length = max_context_length
        self.max_history_length = max_history_length
        self.openai_model = openai_model
        self.temperature = temperature
        self.collection_name = collection_name
        self.embedding_model_name = embedding_model
        self.diversity_factor = diversity_factor
        
        # Sohbet geÃ§miÅŸi iÃ§in deÄŸiÅŸkenler
        self.conversation_history = []
        self.question_history = []  # Sorulan sorularÄ±n geÃ§miÅŸi
        self.used_sources = {}  # Her soru iÃ§in kullanÄ±lan kaynaklarÄ± takip etmek iÃ§in
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"RAGChatbot baÅŸlatÄ±lÄ±yor...")
        
        # OpenAI API anahtarÄ±nÄ± kontrol et
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        
        # OpenAI API kullanÄ±mÄ±
        if not self.openai_api_key:
            self.logger.warning("OPENAI_API_KEY bulunamadÄ±! HuggingFace embeddings kullanÄ±lacak.")
            # OpenAI olmadan da Ã§alÄ±ÅŸabilmesi iÃ§in varsayÄ±lan bir LLM ayarla
            # Bu durumda sadece embedding iÅŸlemleri iÃ§in HuggingFace kullanÄ±lacak
            self.llm = None
        else:
            self.logger.info(f"OpenAI modeli kullanÄ±lÄ±yor: {self.openai_model}")
            try:
                self.llm = ChatOpenAI(
                    model=self.openai_model,
                    temperature=self.temperature,
                    max_tokens=1024
                )
            except Exception as e:
                self.logger.error(f"OpenAI modeli yÃ¼klenirken hata: {str(e)}")
                self.llm = None
        
        # Embedding modeli
        try:
            if "openai" in self.embedding_model_name.lower() or "text-embedding" in self.embedding_model_name.lower():
                # OpenAI API anahtarÄ± yoksa HuggingFace'e geÃ§
                if not self.openai_api_key:
                    self.logger.warning(f"OpenAI API anahtarÄ± bulunamadÄ±! HuggingFace embedding modeline geÃ§iliyor.")
                    self.embedding_model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
                    self.embeddings = HuggingFaceEmbeddings(
                        model_name=self.embedding_model_name
                    )
                else:
                    self.logger.info(f"OpenAI Embeddings kullanÄ±lÄ±yor: {self.embedding_model_name}")
                    self.embeddings = OpenAIEmbeddings(
                        model=self.embedding_model_name
                    )
            else:
                self.logger.info(f"HuggingFace Embeddings kullanÄ±lÄ±yor: {self.embedding_model_name}")
                self.embeddings = HuggingFaceEmbeddings(
                    model_name=self.embedding_model_name
                )
        except Exception as e:
            self.logger.error(f"Embedding modeli yÃ¼klenirken hata: {str(e)}")
            # Hata durumunda varsayÄ±lan HuggingFace modeline geÃ§
            try:
                self.logger.warning("VarsayÄ±lan HuggingFace embedding modeline geÃ§iliyor...")
                self.embedding_model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
                self.embeddings = HuggingFaceEmbeddings(
                    model_name=self.embedding_model_name
                )
            except Exception as fallback_error:
                self.logger.error(f"VarsayÄ±lan embedding modeli yÃ¼klenirken hata: {str(fallback_error)}")
                raise
            
        # VektÃ¶r veritabanÄ±nÄ± yÃ¼kle
        self.vector_store = None
        self._load_vector_store()
        
        # SÄ±ÄŸÄ±nma evleri ve danÄ±ÅŸma merkezleri verilerini yÃ¼kle
        self.siginma_evleri = []
        self.danisma_merkezleri = []
        self._load_shelter_data()
        
    def _load_vector_store(self):
        """VektÃ¶r veritabanÄ±nÄ± yÃ¼kle"""
        try:
            vector_store_path = self.vector_store_path / self.collection_name
            self.logger.info(f"VektÃ¶r veritabanÄ± yÃ¼kleniyor: {vector_store_path}")
            
            if not vector_store_path.exists():
                self.logger.warning(f"VektÃ¶r veritabanÄ± bulunamadÄ±: {vector_store_path}")
                self.vector_store = None
                return
                
            if self.vector_db_type.lower() == "chroma":
                self.logger.info("Chroma vektÃ¶r veritabanÄ± kullanÄ±lÄ±yor")
                self.vector_store = Chroma(
                    persist_directory=str(vector_store_path),
                    embedding_function=self.embeddings,
                    collection_name=self.collection_name
                )
            elif self.vector_db_type.lower() == "faiss":
                self.logger.info("FAISS vektÃ¶r veritabanÄ± kullanÄ±lÄ±yor")
                # FAISS iÃ§in index_name parametresi yok, doÄŸrudan dizin yolunu kullanÄ±r
                try:
                    self.vector_store = FAISS.load_local(
                        folder_path=str(vector_store_path),
                        embeddings=self.embeddings,
                        index_name=self.collection_name
                    )
                except Exception as e:
                    self.logger.error(f"FAISS veritabanÄ± yÃ¼klenirken hata: {str(e)}")
                    self.vector_store = None
            else:
                self.logger.error(f"Desteklenmeyen vektÃ¶r veritabanÄ± tÃ¼rÃ¼: {self.vector_db_type}")
                self.vector_store = None
                
            if self.vector_store:
                self.logger.info("VektÃ¶r veritabanÄ± baÅŸarÄ±yla yÃ¼klendi")
            else:
                self.logger.warning("VektÃ¶r veritabanÄ± yÃ¼klenemedi")
                
        except Exception as e:
            self.logger.error(f"VektÃ¶r veritabanÄ± yÃ¼klenirken hata: {str(e)}")
            self.vector_store = None
            
    def _chunk_documents(self, documents: List[Document]) -> List[List[Document]]:
        """DokÃ¼manlarÄ± daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶ler"""
        if not documents:
            self.logger.warning("ParÃ§alanacak dokÃ¼man bulunamadÄ±!")
            return []
        
        # Belgeleri daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶l
        # OpenAI API'nin token limitini aÅŸmamak iÃ§in (300.000 token)
        # Daha kÃ¼Ã§Ã¼k parÃ§alar kullanalÄ±m (her parÃ§ada maksimum 10 belge)
        chunk_size = 10
        chunks = []
        
        # Ã–nce belgeleri boyutlarÄ±na gÃ¶re sÄ±ralayarak bÃ¼yÃ¼k belgeleri bÃ¶lelim
        # Bu, token limitini aÅŸma riskini azaltacaktÄ±r
        sorted_docs = sorted(documents, key=lambda doc: len(doc.page_content))
        
        # Toplam tahmini token sayÄ±sÄ±nÄ± hesapla (yaklaÅŸÄ±k olarak 4 karakter = 1 token)
        current_chunk = []
        current_token_estimate = 0
        max_tokens_per_chunk = 150000  # Limit 300.000, ama daha fazla marj bÄ±rakalÄ±m
        
        for doc in sorted_docs:
            # Belgenin tahmini token sayÄ±sÄ±nÄ± hesapla
            doc_token_estimate = len(doc.page_content) // 4
            
            # EÄŸer belge tek baÅŸÄ±na Ã§ok bÃ¼yÃ¼kse, onu metin olarak parÃ§alara bÃ¶l
            if doc_token_estimate > max_tokens_per_chunk:
                self.logger.warning(f"BÃ¼yÃ¼k belge tespit edildi: {doc_token_estimate} tahmini token. ParÃ§alara bÃ¶lÃ¼nÃ¼yor.")
                # Belgeyi metin olarak parÃ§alara bÃ¶l
                text_chunks = [doc.page_content[i:i + max_tokens_per_chunk * 4] for i in range(0, len(doc.page_content), max_tokens_per_chunk * 4)]
                
                # Her metin parÃ§asÄ± iÃ§in yeni bir belge oluÅŸtur
                for i, text_chunk in enumerate(text_chunks):
                    new_doc = Document(
                        page_content=text_chunk,
                        metadata={**doc.metadata, "chunk": i, "total_chunks": len(text_chunks)}
                    )
                    # Yeni belgeyi ekle
                    if current_token_estimate + (len(text_chunk) // 4) > max_tokens_per_chunk and current_chunk:
                        chunks.append(current_chunk)
                        current_chunk = []
                        current_token_estimate = 0
                    
                    current_chunk.append(new_doc)
                    current_token_estimate += len(text_chunk) // 4
            else:
                # Normal boyuttaki belgeleri ekle
                if current_token_estimate + doc_token_estimate > max_tokens_per_chunk and current_chunk:
                    chunks.append(current_chunk)
                    current_chunk = []
                    current_token_estimate = 0
                
                current_chunk.append(doc)
                current_token_estimate += doc_token_estimate
        
        # Son parÃ§ayÄ± ekle
        if current_chunk:
            chunks.append(current_chunk)
        
        self.logger.info(f"DokÃ¼manlar {len(chunks)} parÃ§aya bÃ¶lÃ¼ndÃ¼")
        return chunks

    def create_vector_store(self, documents: List[Document]) -> bool:
        """
        DokÃ¼manlarÄ± kullanarak vektÃ¶r veritabanÄ± oluÅŸturur.
        
        Args:
            documents: VektÃ¶r veritabanÄ±na eklenecek dokÃ¼manlar
            
        Returns:
            bool: Ä°ÅŸlemin baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±
        """
        try:
            self.logger.info(f"Yeni vektÃ¶r veritabanÄ± oluÅŸturuluyor: {self.vector_store_path}")
            
            # String tipindeki dokÃ¼manlarÄ± filtrele, sadece Document nesnelerini kullan
            valid_documents = []
            for doc in documents:
                if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):
                    valid_documents.append(doc)
                else:
                    self.logger.warning(f"GeÃ§ersiz dokÃ¼man tipi atlandÄ±: {type(doc)}")
            
            if not valid_documents:
                self.logger.error("GeÃ§erli dokÃ¼man bulunamadÄ±!")
                return False
                
            # DokÃ¼manlarÄ± parÃ§alara bÃ¶l
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=2000,
                chunk_overlap=200,
                separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
                length_function=len
            )
            
            split_docs = text_splitter.split_documents(valid_documents)
            self.logger.info(f"DokÃ¼manlar {len(split_docs)} parÃ§aya bÃ¶lÃ¼ndÃ¼")
            
            # KarmaÅŸÄ±k metadata deÄŸerlerini filtrele
            filtered_docs = []
            for doc in split_docs:
                # Metadata'daki karmaÅŸÄ±k deÄŸerleri filtrele
                doc.metadata = filter_complex_metadata(doc.metadata)
                filtered_docs.append(doc)
            
            # VektÃ¶r veritabanÄ± tipine gÃ¶re oluÅŸtur
            if self.vector_db_type.lower() == "chroma":
                self.logger.info("Chroma vektÃ¶r veritabanÄ± oluÅŸturuluyor")
                try:
                    # Chroma vektÃ¶r veritabanÄ± oluÅŸtur
                    vector_db = Chroma.from_documents(
                        documents=filtered_docs,
                        embedding=self.embeddings,
                        persist_directory=self.vector_store_path,
                        collection_name=self.collection_name
                    )
                    vector_db.persist()
                    self.logger.info(f"Chroma vektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu: {self.vector_store_path}")
                    return True
                except Exception as e:
                    self.logger.error(f"Chroma vektÃ¶r veritabanÄ± oluÅŸturulurken hata: {str(e)}")
                    return False
            elif self.vector_db_type.lower() == "faiss":
                self.logger.info(f"FAISS vektÃ¶r veritabanÄ± oluÅŸturuluyor")
                try:
                    # FAISS vektÃ¶r veritabanÄ± oluÅŸtur
                    vector_db = FAISS.from_documents(
                        documents=filtered_docs,
                        embedding=self.embeddings
                    )
                    
                    # FAISS'i kaydet
                    vector_db.save_local(self.vector_store_path, index_name=self.collection_name)
                    self.logger.info(f"FAISS vektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu: {self.vector_store_path}")
                    return True
                except Exception as e:
                    self.logger.error(f"FAISS vektÃ¶r veritabanÄ± oluÅŸturulurken hata: {str(e)}")
                    return False
            else:
                self.logger.error(f"Desteklenmeyen vektÃ¶r veritabanÄ± tÃ¼rÃ¼: {self.vector_db_type}")
                return False
        except Exception as e:
            self.logger.error(f"VektÃ¶r veritabanÄ± oluÅŸturulurken hata: {str(e)}")
            return False
            
    def get_context(self, query: str, k: int = 8):
        """Verilen sorgu iÃ§in vektÃ¶r veritabanÄ±ndan baÄŸlam dÃ¶kÃ¼manlarÄ± alÄ±r"""
        if not self.vector_store:
            self.logger.warning("VektÃ¶r veritabanÄ± yÃ¼klenmedi!")
            return []
            
        try:
            self.logger.info(f"Sorgu iÃ§in baÄŸlam aranÄ±yor: {query}")
            
            # Ã–zel anahtar kelimeleri kontrol et
            special_keywords = {
                "sÄ±ÄŸÄ±nma": ["sÄ±ÄŸÄ±nma", "sÄ±ÄŸÄ±nak", "sÄ±ÄŸÄ±nmaevi", "kadÄ±n sÄ±ÄŸÄ±nmaevi", "adres", "yer", "nere", "nerede", "listele", "gidebileceÄŸim"],
                "destek": ["destek", "yardÄ±m", "danÄ±ÅŸma", "merkez", "telefon", "hat", "numara", "iletiÅŸim"],
                "yasal": ["yasal", "hukuk", "kanun", "hak", "dava", "baÅŸvuru", "haklar", "yasal haklar", "baÅŸvurabilirim"],
                "acil": ["acil", "tehlike", "koruma", "polis", "jandarma", "112", "155", "tehdit", "tehlikede"],
                "taciz": ["taciz", "tacize uÄŸradÄ±m", "cinsel taciz", "sÃ¶zlÃ¼ taciz", "fiziksel taciz", "tacize maruz kaldÄ±m"],
                "ÅŸiddet": ["ÅŸiddet", "ÅŸiddete uÄŸradÄ±m", "dayak", "darp", "fiziksel ÅŸiddet", "psikolojik ÅŸiddet", "ekonomik ÅŸiddet"]
            }
            
            # Sorgu iÃ§in ek arama terimleri oluÅŸtur
            enhanced_queries = [query]
            
            # Sorgu iÃ§inde Ã¶zel anahtar kelimeler varsa, ek sorgular oluÅŸtur
            detected_categories = []
            for category, keywords in special_keywords.items():
                if any(keyword in query.lower() for keyword in keywords):
                    detected_categories.append(category)
            
            # Taciz ve sÄ±ÄŸÄ±nma birlikte geÃ§iyorsa Ã¶zel iÅŸlem yap
            if "taciz" in detected_categories and "sÄ±ÄŸÄ±nma" in detected_categories:
                enhanced_queries.append("taciz durumunda sÄ±ÄŸÄ±nabilecek yerler")
                enhanced_queries.append("kadÄ±n sÄ±ÄŸÄ±nma evleri adresleri")
                enhanced_queries.append("taciz maÄŸdurlarÄ± iÃ§in destek merkezleri")
                enhanced_queries.append("ÅÃ–NÄ°M adresleri")
            
            # Åiddet ve sÄ±ÄŸÄ±nma birlikte geÃ§iyorsa Ã¶zel iÅŸlem yap
            if "ÅŸiddet" in detected_categories and "sÄ±ÄŸÄ±nma" in detected_categories:
                enhanced_queries.append("ÅŸiddet durumunda sÄ±ÄŸÄ±nabilecek yerler")
                enhanced_queries.append("kadÄ±n sÄ±ÄŸÄ±nma evleri adresleri")
                enhanced_queries.append("ÅŸiddet maÄŸdurlarÄ± iÃ§in destek merkezleri")
                enhanced_queries.append("ÅÃ–NÄ°M adresleri")
            
            # Tek tek kategorileri iÅŸle
            for category in detected_categories:
                if category == "sÄ±ÄŸÄ±nma":
                    enhanced_queries.append("kadÄ±n sÄ±ÄŸÄ±nma evleri adresleri")
                    enhanced_queries.append("sÄ±ÄŸÄ±nma evi baÅŸvuru")
                    enhanced_queries.append("ÅÃ–NÄ°M adresleri")
                    enhanced_queries.append("kadÄ±n danÄ±ÅŸma merkezleri")
                elif category == "destek":
                    enhanced_queries.append("kadÄ±n destek hatlarÄ± ve merkezleri")
                    enhanced_queries.append("psikolojik destek hatlarÄ±")
                elif category == "yasal":
                    enhanced_queries.append("kadÄ±na yÃ¶nelik ÅŸiddet yasal haklar")
                    enhanced_queries.append("taciz durumunda yasal haklar")
                elif category == "acil":
                    enhanced_queries.append("acil durum kadÄ±n destek hatlarÄ±")
                    enhanced_queries.append("acil durum telefon numaralarÄ±")
                elif category == "taciz":
                    enhanced_queries.append("taciz durumunda ne yapmalÄ±")
                    enhanced_queries.append("taciz maÄŸdurlarÄ± iÃ§in destek")
                elif category == "ÅŸiddet":
                    enhanced_queries.append("ÅŸiddet durumunda ne yapmalÄ±")
                    enhanced_queries.append("ÅŸiddet maÄŸdurlarÄ± iÃ§in destek")
            
            # EÄŸer hiÃ§bir kategori tespit edilmediyse, genel sorgular ekle
            if not detected_categories:
                enhanced_queries.append("kadÄ±na yÃ¶nelik ÅŸiddet")
                enhanced_queries.append("kadÄ±n destek hatlarÄ±")
                enhanced_queries.append("kadÄ±n sÄ±ÄŸÄ±nma evleri")
            
            # TÃ¼m sorgular iÃ§in dokÃ¼manlarÄ± topla
            all_docs = []
            for enhanced_query in enhanced_queries:
                docs = self.vector_store.similarity_search(enhanced_query, k=k)
                all_docs.extend(docs)
            
            # Tekrarlanan dokÃ¼manlarÄ± kaldÄ±r
            unique_docs = []
            doc_contents = set()
            for doc in all_docs:
                if doc.page_content not in doc_contents:
                    unique_docs.append(doc)
                    doc_contents.add(doc.page_content)
            
            # En fazla 2*k dokÃ¼man dÃ¶ndÃ¼r
            result_docs = unique_docs[:2*k]
            
            self.logger.info(f"{len(result_docs)} adet baÄŸlam dokÃ¼manÄ± bulundu")
            return result_docs
        except Exception as e:
            self.logger.error(f"BaÄŸlam aranÄ±rken hata: {str(e)}")
            return []
            
    def add_to_history(self, role: str, content: str):
        """
        Sohbet geÃ§miÅŸine yeni bir mesaj ekler.
        
        Args:
            role: MesajÄ±n sahibi ("user" veya "assistant")
            content: Mesaj iÃ§eriÄŸi
        """
        self.conversation_history.append({"role": role, "content": content})
        # GeÃ§miÅŸ uzunluÄŸunu kontrol et ve gerekirse kÄ±rp
        if len(self.conversation_history) > self.max_history_length * 2:  # Her soru-cevap Ã§ifti iÃ§in 2 mesaj
            self.conversation_history = self.conversation_history[-self.max_history_length*2:]
            
    def get_conversation_context(self):
        """
        Sohbet geÃ§miÅŸinden bir baÄŸlam metni oluÅŸturur.
        
        Returns:
            Sohbet geÃ§miÅŸini iÃ§eren bir metin
        """
        if not self.conversation_history:
            return ""
            
        context = "Ã–nceki konuÅŸma:\n"
        for message in self.conversation_history:
            role = "KullanÄ±cÄ±" if message["role"] == "user" else "Asistan"
            context += f"{role}: {message['content']}\n\n"
            
        return context
        
    # Sabit deÄŸerler - sÄ±nÄ±fÄ±n en Ã¼stÃ¼nde tanÄ±mlanmalÄ±
    SHELTER_KEYWORDS = [
        "sÄ±ÄŸÄ±nma", "sÄ±ÄŸÄ±nak", "sÄ±ÄŸÄ±nmaevi", "konukevi", "kadÄ±n sÄ±ÄŸÄ±nmaevi", 
        "sÄ±ÄŸÄ±nabileceÄŸim", "sÄ±ÄŸÄ±nabilir miyim", "nereye gidebilirim", "nerede kalabilirim",
        "ÅŸÃ¶nim", "koruma", "barÄ±nma", "kadÄ±n konukevi", "gidebileceÄŸim yer", "barÄ±nma kuruluÅŸlarÄ±"
    ]

    COUNSELING_KEYWORDS = [
        "danÄ±ÅŸma", "destek", "merkez", "danÄ±ÅŸma merkezi", "kadÄ±n danÄ±ÅŸma", 
        "danÄ±ÅŸabileceÄŸim", "yardÄ±m alabileceÄŸim", "baÅŸvurabileceÄŸim", "destek hattÄ±",
        "danÄ±ÅŸmanlÄ±k", "mor Ã§atÄ±", "kadÄ±n dayanÄ±ÅŸma", "kadav"
    ]

    BIG_CITIES = ["istanbul", "ankara", "izmir", "bursa", "antalya"]

    EMERGENCY_NUMBERS = {
        "Alo 183": "Sosyal Destek HattÄ± (7/24)",
        "155": "Polis Ä°mdat",
        "156": "Jandarma",
        "112": "Acil YardÄ±m"
    }

    # Åiddet ve intihar dÃ¼ÅŸÃ¼nceleri iÃ§in anahtar kelimeler
    CRISIS_KEYWORDS = {
        "violence": [
            "dÃ¶vmek", "vurmak", "Ã¶ldÃ¼rmek", "zarar vermek", "saldÄ±rmak", "ÅŸiddet",
            "kavga", "tartÄ±ÅŸma", "sinir", "Ã¶fke", "nefret", "intikam", "tehdit",
            "kÄ±zmak", "sinirlenmek", "kontrolÃ¼ kaybetmek", "kendimi tutamÄ±yorum",
            "dayanamÄ±yorum", "tahammÃ¼l edemiyorum", "alÄ±koyamÄ±yorum"
        ],
        "suicide": [
            "intihar", "kendime zarar", "Ã¶lmek istiyorum", "yaÅŸamak istemiyorum",
            "canÄ±ma kÄ±ymak", "hayatÄ±ma son vermek", "kendimi Ã¶ldÃ¼rmek",
            "yaÅŸamÄ±n anlamÄ± yok", "deÄŸersizim", "kimse beni sevmiyor"
        ]
    }

    # Psikolojik destek merkezleri
    SUPPORT_RESOURCES = {
        "Psikiyatrik Destek": [
            "TÃ¼rkiye Psikiyatri DerneÄŸi - https://psikiyatri.org.tr",
            "TÃ¼rk Psikologlar DerneÄŸi - https://www.psikolog.org.tr",
            "EMDR DerneÄŸi - https://www.emdr-tr.org"
        ],
        "KadÄ±n Destek": [
            "Mor Ã‡atÄ± KadÄ±n SÄ±ÄŸÄ±naÄŸÄ± VakfÄ± - https://morcati.org.tr",
            "KadÄ±n DayanÄ±ÅŸma VakfÄ± - https://www.kadindayanismavakfi.org.tr",
            "KAMER VakfÄ± - https://www.kamer.org.tr"
        ],
        "Acil YardÄ±m": [
            "Alo 183 - Sosyal Destek HattÄ± (7/24)",
            "155 - Polis Ä°mdat",
            "112 - Acil YardÄ±m"
        ]
    }
    
    def chat(self, query: str, **kwargs):
        """
        KullanÄ±cÄ± mesajÄ±nÄ± sohbet geÃ§miÅŸine ekler ve yanÄ±t Ã¼retir.
        AynÄ± veya benzer sorulara farklÄ± yanÄ±tlar Ã¼retmek iÃ§in Ã§eÅŸitlilik mekanizmasÄ± kullanÄ±r.
        
        Args:
            query: KullanÄ±cÄ± mesajÄ±
            **kwargs: generate_response fonksiyonuna geÃ§irilecek ek parametreler
            
        Returns:
            Tuple[str, List[str]]: (AsistanÄ±n yanÄ±tÄ±, KullanÄ±lan kaynaklar listesi)
        """
        # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
        self.add_to_history("user", query)
        
        try:
            # Benzer soru kontrolÃ¼ yap
            is_similar, similar_question = self._is_similar_question(query)
            
            # Benzer soru varsa Ã§eÅŸitlilik saÄŸla
            if is_similar and similar_question:
                context = self._get_diverse_context(query, similar_question)
                response, sources = self.generate_response(query, context=context, **kwargs)
            else:
                # Normal yanÄ±t Ã¼ret
                response, sources = self.generate_response(query, **kwargs)
            
            # Asistan yanÄ±tÄ±nÄ± geÃ§miÅŸe ekle
            self.add_to_history("assistant", response)
            
            # KullanÄ±lan kaynaklarÄ± kaydet
            self.used_sources[query] = sources
            
            return response, sources
            
        except Exception as e:
            self.logger.error(f"Chat yanÄ±tÄ± oluÅŸturulurken hata: {str(e)}")
            error_message = f"ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturulurken bir hata meydana geldi: {str(e)}"
            self.add_to_history("assistant", error_message)
            return error_message, []

    def _normalize_city(self, text: str) -> str:
        """TÃ¼rkÃ§e karakterleri normalize et ve kÃ¼Ã§Ã¼k harfe Ã§evir"""
        import unicodedata
        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8').lower()
        return text.replace('iÌ‡', 'i')  # TÃ¼rkÃ§ede bazen iÌ‡ harfi farklÄ± kodlanÄ±yor

    def _find_city_in_query(self, query: str) -> Optional[str]:
        """Sorguda ÅŸehir adÄ± geÃ§iyor mu, fuzzy matching ile bul"""
        from difflib import get_close_matches
        query_norm = self._normalize_city(query)
        all_cities = [self._normalize_city(s.get("city", "")) for s in self.siginma_evleri]
        matches = get_close_matches(query_norm, all_cities, n=1, cutoff=0.8)
        return matches[0] if matches else None

    def _format_contact_info(self, contact_dict: dict) -> str:
        """Telefon, adres ve iletiÅŸim bilgilerini formatla"""
        info = ""
        if phone := contact_dict.get('phone'):
            if isinstance(phone, list):
                info += f"ğŸ“ Telefon: {', '.join(phone)}\n"
            else:
                info += f"ğŸ“ Telefon: {phone}\n"
        if address := contact_dict.get('address'):
            info += f"ğŸ“ Adres: {address}\n"
        if email := contact_dict.get('email'):
            info += f"ğŸ“§ E-posta: {email}\n"
        if website := contact_dict.get('website'):
            info += f"ğŸŒ Web: {website}\n"
        return info

    def _is_similar_question(self, query: str) -> Tuple[bool, Optional[str]]:
        """Benzer soru kontrolÃ¼ yap ve Ã§eÅŸitlilik saÄŸla

        Args:
            query (str): KullanÄ±cÄ± sorusu

        Returns:
            Tuple[bool, Optional[str]]: Benzerlik durumu ve benzer soru
        """
        try:
            if not self.question_history:
                return False, None

            # Son 5 soruyu kontrol et
            recent_questions = self.question_history[-5:]
            for prev_question in recent_questions:
                similarity = self._calculate_similarity(query, prev_question)
                if similarity > 0.85:  # YÃ¼ksek benzerlik eÅŸiÄŸi
                    return True, prev_question
            return False, None

        except Exception as e:
            self.logger.error(f"Benzer soru kontrolÃ¼nde hata: {str(e)}")
            return False, None

    def _get_diverse_context(self, query: str, similar_question: str) -> List[Document]:
        """Benzer sorular iÃ§in farklÄ± baÄŸlam belgelerini getir

        Args:
            query (str): Yeni soru
            similar_question (str): Benzer eski soru

        Returns:
            List[Document]: Ã‡eÅŸitlendirilmiÅŸ baÄŸlam belgeleri
        """
        try:
            # Ana baÄŸlamÄ± al
            main_context = self.get_context(query)
            
            # Benzer sorunun kullandÄ±ÄŸÄ± kaynaklarÄ± al
            used_sources = self.used_sources.get(similar_question, [])
            
            # Yeni kaynaklarÄ± Ã¶nceliklendir
            diverse_context = [
                doc for doc in main_context 
                if doc.metadata.get('source') not in used_sources
            ]
            
            # Yeterli baÄŸlam yoksa orijinal baÄŸlamÄ± kullan
            if len(diverse_context) < 3:
                diverse_context.extend(main_context[:3])
                
            return diverse_context[:5]  # En fazla 5 baÄŸlam belgesi dÃ¶ndÃ¼r

        except Exception as e:
            self.logger.error(f"Ã‡eÅŸitli baÄŸlam alÄ±nÄ±rken hata: {str(e)}")
            return self.get_context(query)  # Hata durumunda normal baÄŸlamÄ± dÃ¶ndÃ¼r

    def _get_system_message(self) -> dict:
        """Sistem mesajÄ±nÄ± hazÄ±rla
        
        Returns:
            dict: Sistem mesajÄ±
        """
        system_content = """Sen kadÄ±na yÃ¶nelik ÅŸiddet, taciz, yasal haklar ve psikolojik destek konularÄ±nda uzmanlaÅŸmÄ±ÅŸ, empatik ve bilgili bir TÃ¼rkÃ§e destek chatbotusun. Ä°leri dÃ¼zeyde bilgi iÅŸleme ve analiz yeteneÄŸine sahipsin. VektÃ¶r veritabanÄ±ndaki bilgileri akÄ±llÄ±ca kullanarak, her soruda Ã¶zgÃ¼n ve duruma Ã¶zel yanÄ±tlar Ã¼retebilirsin.

AmacÄ±n, ÅŸiddet veya taciz maÄŸduru kiÅŸilere doÄŸru, kapsamlÄ± ve destekleyici yanÄ±tlar vermek; onlara gÃ¼venli kaynaklar sunarak yardÄ±mcÄ± olmaktÄ±r. Kendini gizlemeyen, aÃ§Ä±k, gÃ¼venilir ve kararlÄ± bir destekÃ§i gibi davranmalÄ±sÄ±n. YanÄ±tlarÄ±nda asla suÃ§layÄ±cÄ± veya nÃ¶tr kalma; her zaman destekleyici ol.

### ÅÄ°DDET UYGULAYAN KÄ°ÅÄ°LERE YAKLAÅIM ###
Åiddet uygulayan, Ã¶fke kontrolÃ¼ sorunu yaÅŸayan veya kendine zarar verme eÄŸilimi olan kiÅŸilere aÅŸaÄŸÄ±daki ilkeler doÄŸrultusunda yanÄ±t ver:

1. **SuÃ§layÄ±cÄ± Olmadan YÃ¶nlendirme:** KiÅŸiyi suÃ§lamadan, davranÄ±ÅŸÄ±nÄ±n ciddiyetini anlamasÄ±nÄ± saÄŸla ve profesyonel yardÄ±m almanÄ±n Ã¶nemini vurgula.

2. **Acil Profesyonel Destek:** Ã–fke kontrolÃ¼, psikolojik destek ve terapi iÃ§in baÅŸvurabilecekleri kurumlarÄ± ve uzmanlarÄ± Ã¶ner.

3. **Sorumluluk Bilinci:** KiÅŸinin kendi davranÄ±ÅŸlarÄ±ndan sorumlu olduÄŸunu nazikÃ§e hatÄ±rlat, ancak deÄŸiÅŸim iÃ§in umut olduÄŸunu da vurgula.

4. **Somut AdÄ±mlar:** Ã–fke anÄ±nda yapabilecekleri pratik teknikler Ã¶ner (ortamdan uzaklaÅŸma, nefes egzersizleri, vb.).

5. **Ä°ntihar veya Kendine Zarar Verme DurumlarÄ±nda:** Acil yardÄ±m hatlarÄ±nÄ± (112, 183) aramasÄ±nÄ± Ã¶ner ve durumun ciddiyetini vurgula.

###  SIÄINMA EVLERÄ° VE DANIÅMA MERKEZLERÄ° BÄ°LGÄ°LERÄ° ###
KullanÄ±cÄ± sÄ±ÄŸÄ±nma evleri, konukevleri, ÅÃ–NÄ°M (Åiddet Ã–nleme ve Ä°zleme Merkezi) veya kadÄ±n danÄ±ÅŸma merkezleri hakkÄ±nda sorduÄŸunda, MUTLAKA aÅŸaÄŸÄ±daki bilgileri iÃ§eren yanÄ±tlar ver:

1. **DoÄŸrudan Ä°letiÅŸim Bilgileri:** Telefon numaralarÄ±, adresler ve varsa web siteleri gibi doÄŸrudan iletiÅŸim bilgilerini paylaÅŸ. Sadece genel bilgi verme, somut iletiÅŸim bilgilerini mutlaka ekle. BaÄŸlamda verilen JSON verilerinden (siginma_evleri.json ve kadin_danisma_merkezleri.json) gerÃ§ek iletiÅŸim bilgilerini kullan.

2. **Acil YardÄ±m HatlarÄ±:** Her zaman ÅŸu acil yardÄ±m hatlarÄ±nÄ± da ekle:
   - Alo 183 Sosyal Destek HattÄ±
   - 155 Polis Ä°mdat
   - 156 Jandarma
   - 112 Acil YardÄ±m

3. **Åehir BazlÄ± Bilgiler:** KullanÄ±cÄ± belirli bir ÅŸehir belirtirse veya konuÅŸma sÄ±rasÄ±nda bir ÅŸehir adÄ± geÃ§erse, o ÅŸehirdeki sÄ±ÄŸÄ±nma evleri ve danÄ±ÅŸma merkezlerinin iletiÅŸim bilgilerini detaylÄ± olarak paylaÅŸ:
   - Åehir adÄ±nÄ± aÃ§Ä±kÃ§a belirt: "**Ä°STANBUL'DAKÄ° DESTEK MERKEZLERÄ°**"
   - JSON verilerindeki gerÃ§ek telefon numaralarÄ±nÄ±, adresleri ve web sitelerini eksiksiz olarak ver
   - Belirsiz ifadeler kullanma ("tam adres belirtilmeli" veya "doÄŸru numara iÃ§in yerel iletiÅŸim bilgilerini kontrol etmenizi Ã¶neririm" gibi)
   - Her merkez iÃ§in Ã§alÄ±ÅŸma saatleri, sunulan hizmetler (hukuki danÄ±ÅŸmanlÄ±k, psikolojik destek, sosyal destek) gibi ek bilgileri de ekle
   - BÃ¼yÃ¼k ÅŸehirlerde (Istanbul, Ankara, Izmir, Bursa, Antalya) ilÃ§e bazlÄ± bilgileri de dÃ¼zenle: "**KadÄ±kÃ¶y'deki Merkezler:**", "**BeÅŸiktaÅŸ'taki Merkezler:**" gibi

4. **BaÄŸÄ±msÄ±z KadÄ±n Ã–rgÃ¼tleri:** Mor Ã‡atÄ±, KadÄ±n DayanÄ±ÅŸma VakfÄ± gibi baÄŸÄ±msÄ±z kadÄ±n Ã¶rgÃ¼tlerinin iletiÅŸim bilgilerini de ekle.

5. **Hem JSON Verileri Hem Web KaynaklarÄ±:** YanÄ±tlarÄ±nda hem JSON verilerindeki somut bilgileri hem de vektÃ¶r veritabanÄ±ndaki web kaynaklarÄ±ndan elde edilen bilgileri birleÅŸtir. Ã–nce somut iletiÅŸim bilgilerini ver, sonra web kaynaklarÄ±ndan elde edilen ek bilgileri ekle.

Ã–rnek yanÄ±t formatÄ±:
"Size yardÄ±mcÄ± olabilecek sÄ±ÄŸÄ±nma evleri ve destek hatlarÄ± ÅŸunlardÄ±r:

**Konya ÅÃ–NÄ°M:**
Telefon: 0332 322 76 69
Adres: KÄ±lÄ±Ã§aslan Mah. BediÃ¼zzaman Bulv. No: 83 Merkez, Konya

**Mor Ã‡atÄ± KadÄ±n SÄ±ÄŸÄ±naÄŸÄ± VakfÄ±:**
Telefon: 0212 292 52 31, 0212 292 52 32
Adres: Katip Mustafa Ã‡elebi Mah. Anadolu Sok. No:23 D:7-8 BeyoÄŸlu, Ä°stanbul
Web: https://morcati.org.tr

**Acil YardÄ±m HatlarÄ±:**
- Alo 183 Sosyal Destek HattÄ±
- 155 Polis Ä°mdat
- 156 Jandarma
- 112 Acil YardÄ±m

AyrÄ±ca, web kaynaklarÄ±ndan elde ettiÄŸim bilgilere gÃ¶re, Konya'da baÅŸvurabileceÄŸiniz diÄŸer destek kuruluÅŸlarÄ± ÅŸunlardÄ±r: [web kaynaklarÄ±ndan elde edilen ek bilgiler]"


###  BÄ°LGÄ° Ä°ÅLEME VE KAYNAK KULLANIMI ###
1. **AkÄ±llÄ± Bilgi Sentezi:** VektÃ¶r veritabanÄ±ndaki bilgileri sadece kopyalayÄ±p yapÄ±ÅŸtÄ±rma. FarklÄ± kaynaklardan gelen bilgileri analiz et, sentezle ve kullanÄ±cÄ±nÄ±n sorusuna Ã¶zel bir yanÄ±t oluÅŸtur.

2. **BaÄŸlam DuyarlÄ± YanÄ±tlar:** Her soruyu baÄŸlamÄ± iÃ§inde deÄŸerlendir. KullanÄ±cÄ±nÄ±n Ã¶nceki sorularÄ±nÄ± ve yanÄ±tlarÄ±nÄ± hatÄ±rla, sÃ¶yleÅŸimin akÄ±ÅŸÄ±na uygun yanÄ±tlar ver.

3. **GÃ¼ncel ve DoÄŸru Bilgi:** Yasal mevzuat, kurum bilgileri ve destek hatlarÄ± gibi kritik bilgileri doÄŸru ve gÃ¼ncel ÅŸekilde aktar. Belirsiz veya Ã§eliÅŸkili bilgilerle karÅŸÄ±laÅŸÄ±rsan, en gÃ¼venilir kaynaÄŸÄ± tercih et.

4. **Yerel Bilgi Entegrasyonu:** KullanÄ±cÄ±nÄ±n bulunduÄŸu ÅŸehir veya bÃ¶lgeye Ã¶zel bilgiler (yerel destek hatlarÄ±, sÄ±ÄŸÄ±nma evleri, danÄ±ÅŸma merkezleri) varsa bunlarÄ± yanÄ±tÄ±na dahil et.

###  Ã‡EÅÄ°TLÄ°LÄ°K VE FARKLI YANITLAR ###
1. **YanÄ±t Rotasyonu:** AynÄ± veya benzer sorulara her defasÄ±nda farklÄ± bir yanÄ±t Ã¼ret. Bir soruya daha Ã¶nce verdiÄŸin yanÄ±tÄ± tekrarlama.

2. **Kaynak Ã‡eÅŸitlendirme:** Her yanÄ±tta farklÄ± kaynaklarÄ± Ã¶ne Ã§Ä±kar. Bir kaynaktan sÃ¼rekli alÄ±ntÄ± yapmak yerine, farklÄ± kaynaklardan bilgileri dengeli ÅŸekilde kullan.

3. **Perspektif DeÄŸiÅŸimi:** AynÄ± konuyu farklÄ± aÃ§Ä±lardan ele al. Ã–rneÄŸin, bir soruda yasal boyutu Ã¶ne Ã§Ä±karÄ±rken, benzer bir soruda psikolojik veya sosyal boyutu vurgula.

4. **Bilgi DerinleÅŸtirme:** Her seferinde konunun farklÄ± yÃ¶nlerini derinleÅŸtir. Ã–rneÄŸin ilk yanÄ±tta genel bilgi verirken, sonraki yanÄ±tlarda daha spesifik detaylara odaklan.

5. **Ã–rnekleme Ã‡eÅŸitliliÄŸi:** Her yanÄ±tta farklÄ± Ã¶rnekler, vakalar veya senaryolar kullan. AynÄ± Ã¶rnekleri tekrar etme.

###  YANIT VERME STRATEJÄ°LERÄ° ###
1. **Empati ve Destek Dengesi:** Duygusal destek ile pratik bilgi arasÄ±nda denge kur. Sadece empati kurmakla kalma, somut adÄ±mlar ve Ã§Ã¶zÃ¼mler de sun.

2. **KiÅŸiselleÅŸtirilmiÅŸ YardÄ±m ve YanÄ±tlar:** 
   - Standart, ÅŸablon yanÄ±tlardan kesinlikle kaÃ§Ä±n
   - Her yanÄ±tÄ± sorunun iÃ§eriÄŸine, kullanÄ±cÄ±nÄ±n durumuna ve ihtiyaÃ§larÄ±na gÃ¶re Ã¶zelleÅŸtir
   - KullanÄ±cÄ±nÄ±n duygusal durumunu analiz et ve buna uygun bir ton kullan (korku iÃ§indeyse sakinleÅŸtirici, bilgi arÄ±yorsa bilgilendirici, Ã§aresizse gÃ¼Ã§lendirici)
   - KullanÄ±cÄ±nÄ±n yaÅŸadÄ±ÄŸÄ± ÅŸiddet tÃ¼rÃ¼ne Ã¶zel yanÄ±tlar ver (fiziksel ÅŸiddet, psikolojik ÅŸiddet, ekonomik ÅŸiddet, dijital ÅŸiddet, Ä±srarlÄ± takip vb.)
   - KullanÄ±cÄ±nÄ±n Ã¶zel durumunu dikkate al (hamilelik, Ã§ocuk sahibi olma, engelli olma, gÃ¶Ã§men olma gibi)
   - AYNI SORUYA HER DEFASINDA FARKLI BÄ°R YANIT VERMEYE Ã‡ALIÅ, KAYNAKLARDAN FARKLI BÄ°LGÄ°LERÄ° Ã–NE Ã‡IKAR
   - KullanÄ±cÄ±nÄ±n sorularÄ±nÄ± ve yanÄ±tlarÄ±nÄ± hatÄ±rla, sÃ¼rekli aynÄ± bilgileri tekrarlama
   - KullanÄ±cÄ±nÄ±n durumuna Ã¶zel pratik Ã§Ã¶zÃ¼mler sun: "Sizin durumunuzda ÅŸu adÄ±mlarÄ± atabilirsiniz:"

3. **Acil Durum Tespiti ve MÃ¼dahalesi:** Soruda 'ÅŸiddet', 'dÃ¶vÃ¼lmek', 'intihar', 'taciz', 'tehdit', 'korku', 'yardÄ±m', 'tehlike', 'acil', 'kaÃ§mak', 'kurtulmak' gibi acil mÃ¼dahale gerektiren ifadeler varsa:
   -  KÄ±sa ve gÃ¼Ã§lÃ¼ bir empati ifadesiyle baÅŸla: "YaÅŸadÄ±ÄŸÄ±nÄ±z durumun ne kadar zor olduÄŸunu anlÄ±yorum ve gÃ¼vende olmanÄ±z en Ã¶nemli Ã¶ncelik."
   -  Acil yardÄ±m hatlarÄ±nÄ± (183, 155, 112) Ã¶ncelikli ve vurgulu olarak belirt: "HEMEN ÅU NUMARALARI ARAYABÄ°LÄ°RSÄ°NÄ°Z:"
   -  KullanÄ±cÄ±nÄ±n belirttiÄŸi veya IP adresinden tespit edilebilen ÅŸehre gÃ¶re en yakÄ±n ÅÃ–NÄ°M, sÄ±ÄŸÄ±nma evi veya kadÄ±n danÄ±ÅŸma merkezi bilgilerini detaylÄ± olarak paylaÅŸ (telefon, adres, Ã§alÄ±ÅŸma saatleri)
   -  Yasal haklarÄ± ve koruma mekanizmalarÄ±nÄ± (6284 sayÄ±lÄ± kanun, uzaklaÅŸtÄ±rma kararÄ±) somut adÄ±mlarla aÃ§Ä±kla: "Åu anda yapabileceÄŸiniz adÄ±mlar:"
   -  GÃ¼venlik planÄ± oluÅŸturmasÄ±na yardÄ±mcÄ± ol: "GÃ¼venliÄŸiniz iÃ§in ÅŸunlarÄ± yapabilirsiniz: Ã–nemli belgeleri hazÄ±r tutun, gÃ¼venli bir yere gitmek iÃ§in plan yapÄ±n..."
   -  Psikolojik destek kaynaklarÄ±nÄ± belirt ve travma durumunda ilk yapÄ±lmasÄ± gerekenleri aÃ§Ä±kla

4. **Bilgi SorularÄ±nda Derinlik:** Bilgi sorularÄ±nda sadece yÃ¼zeysel cevaplar verme. Ã–rneÄŸin "6284 sayÄ±lÄ± kanun nedir?" sorusuna, kanunun tanÄ±mÄ±nÄ±n yanÄ± sÄ±ra, nasÄ±l uygulandÄ±ÄŸÄ±, hangi koruma tedbirlerini iÃ§erdiÄŸi ve baÅŸvuru sÃ¼reÃ§leri hakkÄ±nda da bilgi ver.

5. **Alternatif BakÄ±ÅŸ AÃ§Ä±larÄ±:** KarmaÅŸÄ±k durumlarda farklÄ± seÃ§enekler ve bakÄ±ÅŸ aÃ§Ä±larÄ± sun. KullanÄ±cÄ±ya karar verme sÃ¼recinde yardÄ±mcÄ± ol, ancak onun yerine karar verme.

### BÄ°LGÄ° SUNUMU Ã‡EÅÄ°TLÄ°LÄ°ÄÄ° ###
1. **Format DeÄŸiÅŸimi:** Bilgiyi her seferinde farklÄ± formatlarda sun. Bazen paragraflar, bazen maddeler, bazen soru-cevap formatÄ±, bazen adÄ±m adÄ±m yÃ¶nergeler kullan.

2. **Vurgu DeÄŸiÅŸimi:** Her yanÄ±tta farklÄ± noktalara vurgu yap. AynÄ± bilgileri tekrar etmek yerine, her seferinde farklÄ± yÃ¶nleri Ã¶ne Ã§Ä±kar.

3. **Detay Seviyesi:** YanÄ±tlarÄ±n detay seviyesini deÄŸiÅŸtir. Bazen Ã¶zet bilgi, bazen derinlemesine analiz sun.

4. **AnlatÄ±m TarzÄ±:** AnlatÄ±m tarzÄ±nÄ± Ã§eÅŸitlendir. Bazen daha resmi, bazen daha samimi, bazen daha eÄŸitici, bazen daha motive edici bir dil kullan.

### Ä°LETÄ°ÅÄ°M TARZI VE GÃœÃ‡LENDÄ°RÄ°CÄ° DÄ°L ###

1. **Samimi ve Profesyonel Denge:** 
   - Resmi olmayan ama profesyonel bir dil kullan
   - Teknik terimlerden kaÃ§Ä±n, ancak gerektiÄŸinde aÃ§Ä±klamalarÄ±yla birlikte kullan
   - Hukuki terimleri basitleÅŸtirerek aÃ§Ä±kla: "6284 sayÄ±lÄ± kanun size ÅŸunlarÄ± saÄŸlÄ±yor..."
   - KullanÄ±cÄ±nÄ±n yaÅŸÄ±na ve eÄŸitim dÃ¼zeyine uygun bir dil kullan

2. **GÃ¼Ã§lendirici Dil ve YaklaÅŸÄ±m:** 
   - KullanÄ±cÄ±yÄ± asla pasif bir maÄŸdur olarak gÃ¶sterme
   - Her zaman haklarÄ±nÄ± arayan aktif bir birey olarak gÃ¶r
   - "Yapabilirsiniz", "hakkÄ±nÄ±z var", "seÃ§eneÄŸiniz var", "karar sizin", "kontrol sizdedir" gibi gÃ¼Ã§lendirici ifadeler kullan
   - SuÃ§luluk ve utancÄ± azaltan ifadeler kullan: "YaÅŸadÄ±klarÄ±nÄ±z sizin suÃ§unuz deÄŸil", "YardÄ±m istemek cesaret ister"
   - KÃ¼Ã§Ã¼k adÄ±mlarÄ± kutla ve takdir et: "YardÄ±m aramak iÃ§in attÄ±ÄŸÄ±nÄ±z bu adÄ±m Ã§ok deÄŸerli"

3. **YapÄ±landÄ±rÄ±lmÄ±ÅŸ ve Kolay AnlaÅŸÄ±lÄ±r YanÄ±tlar:** 
   - KarmaÅŸÄ±k bilgileri basit, anlaÅŸÄ±lÄ±r adÄ±mlara bÃ¶l
   - Ã–nemli bilgileri vurgulamak iÃ§in kalÄ±n yazÄ± ve maddeler kullan
   - Acil durumlarda kÄ±sa ve net talimatlar ver: "HEMEN 155'i ARAYIN"
   - Uzun yanÄ±tlarda bile okunabilirliÄŸi korumak iÃ§in paragraflarÄ± kÄ±sa tut

4. **Empatik ve Destekleyici Ton:** 
   - "Sizi anladÄ±ÄŸÄ±mÄ± bilmenizi isterim", "Bu zorlu sÃ¼reÃ§te yanÄ±nÄ±zdayÄ±m", "Cesaretiniz iÃ§in sizi takdir ediyorum" gibi insani ifadeler kullan
   - KullanÄ±cÄ±nÄ±n duygularÄ±nÄ± onaylayan ifadeler kullan: "KorkmanÄ±z Ã§ok doÄŸal", "EndiÅŸelenmeniz anlaÅŸÄ±labilir"
   - Umut veren ama gerÃ§ekÃ§i mesajlar ver: "Bu durumdan Ã§Ä±kÄ±ÅŸ var ve size yardÄ±mcÄ± olabilecek kurumlar mevcut"
   - KullanÄ±cÄ±nÄ±n gÃ¼cÃ¼nÃ¼ ve dayanÄ±klÄ±lÄ±ÄŸÄ±nÄ± vurgula: "Bu adÄ±mÄ± atmanÄ±z bÃ¼yÃ¼k bir cesaret gÃ¶steriyor"

5. **KÃ¼ltÃ¼rel DuyarlÄ±lÄ±k:**
   - TÃ¼rkiye'nin farklÄ± bÃ¶lgelerindeki kÃ¼ltÃ¼rel farklÄ±lÄ±klarÄ± dikkate al
   - Dini veya kÃ¼ltÃ¼rel hassasiyetlere saygÄ± gÃ¶ster
   - FarklÄ± sosyoekonomik durumlar iÃ§in uygulanabilir Ã§Ã¶zÃ¼mler sun

Unutma: Sen sadece bir bilgi kaynaÄŸÄ± deÄŸil, aynÄ± zamanda bir destek sesi, bir umut Ä±ÅŸÄ±ÄŸÄ±sÄ±n. Her yanÄ±tÄ±n, bir kadÄ±nÄ±n hayatÄ±nda olumlu bir fark yaratabilir. Standart cevaplar yerine, her duruma Ã¶zel, dÃ¼ÅŸÃ¼nce dolu ve destekleyici yanÄ±tlar vermeye Ã¶zen gÃ¶ster. AynÄ± soruya her seferinde farklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ± ve bilgi sunarak kullanÄ±cÄ±ya daha kapsamlÄ± destek saÄŸla."""
        
        return {"role": "system", "content": system_content}

    def _create_openai_response(self, query: str, context_text: str, 
                             temperature: Optional[float] = None,
                             use_history: bool = True) -> str:
        """OpenAI API kullanarak yanÄ±t oluÅŸtur

        Args:
            query (str): KullanÄ±cÄ± sorusu
            context_text (str): BaÄŸlam metni
            temperature (Optional[float], optional): SÄ±caklÄ±k parametresi
            use_history (bool, optional): Sohbet geÃ§miÅŸi kullanÄ±lsÄ±n mÄ±

        Returns:
            str: OluÅŸturulan yanÄ±t
        """
        try:
            if not self.openai_api_key or not self.llm:
                raise ValueError("OpenAI API anahtarÄ± veya model bulunamadÄ±")

            # Sistem mesajÄ±nÄ± hazÄ±rla
            system_message = self._get_system_message()
            
            # Sohbet geÃ§miÅŸini ekle
            messages = [system_message]
            if use_history and self.conversation_history:
                messages.extend(self.conversation_history[-5:])  # Son 5 mesaj
            
            # Åiddet/intihar dÃ¼ÅŸÃ¼ncesi kontrolÃ¼
            query_lower = query.lower()
            crisis_type = None
            
            # Åiddet veya intihar dÃ¼ÅŸÃ¼ncesi var mÄ± kontrol et
            for intent_type, keywords in self.CRISIS_KEYWORDS.items():
                if any(keyword in query_lower for keyword in keywords):
                    crisis_type = intent_type
                    break

            # Kriz durumu varsa Ã¶zel sistem mesajÄ± ve baÄŸlam ekle
            if crisis_type:
                crisis_resources = "\n\nDestekleyici Kaynaklar:\n"
                for category, resources in self.SUPPORT_RESOURCES.items():
                    crisis_resources += f"\n{category}:\n"
                    for resource in resources:
                        crisis_resources += f"- {resource}\n"

                context_text += crisis_resources
                
                if crisis_type == "violence":
                    messages.append({"role": "system", "content": (
                        "KullanÄ±cÄ± ÅŸiddet/saldÄ±rganlÄ±k dÃ¼rtÃ¼leri ifade ediyor. "
                        "Empatik ve destekleyici ol. Ã–fke ve saldÄ±rganlÄ±k duygularÄ±nÄ± normalize et. "
                        "YardÄ±m aramanÄ±n deÄŸerli bir adÄ±m olduÄŸunu vurgula. "
                        "Profesyonel destek almayÄ± teÅŸvik et ve kaynaklarÄ± paylaÅŸ."
                    )})
                else:  # suicide
                    messages.append({"role": "system", "content": (
                        "KullanÄ±cÄ± intihar dÃ¼ÅŸÃ¼nceleri ifade ediyor. "
                        "DuygularÄ±nÄ± ciddiye al ve anlayÄ±ÅŸla karÅŸÄ±la. "
                        "YalnÄ±z olmadÄ±ÄŸÄ±nÄ± vurgula. "
                        "Acil yardÄ±m hatlarÄ±nÄ± Ã¶ncelikle paylaÅŸ ve profesyonel destek almaya teÅŸvik et."
                    )})

            # KullanÄ±cÄ± sorusunu ve baÄŸlamÄ± ekle
            user_message = f"BaÄŸlam:\n{context_text}\n\nSoru: {query}"
            messages.append({"role": "user", "content": user_message})
            
            # OpenAI'dan yanÄ±t al
            response = self.llm.chat.completions.create(
                model=self.openai_model,
                messages=messages,
                temperature=temperature or self.temperature,
                max_tokens=1024,
                top_p=0.9,
                frequency_penalty=0.6,
                presence_penalty=0.6
            )
            
            return response.choices[0].message.content

        except Exception as e:
            self.logger.error(f"OpenAI yanÄ±tÄ± oluÅŸturulurken hata: {str(e)}")
            return "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturulurken bir hata meydana geldi."

        
    def generate_response(self, query: str, context: Optional[List[Document]] = None,
            max_new_tokens: int = 1024, temperature: Optional[float] = None,
            top_p: float = 0.9, do_sample: bool = True,
            use_history: bool = True) -> Tuple[str, List[str]]:
        """KullanÄ±cÄ± sorusuna yanÄ±t oluÅŸtur
        
        Args:
            query (str): KullanÄ±cÄ± sorusu
            context (Optional[List[Document]], optional): BaÄŸlam belgeleri
            max_new_tokens (int, optional): Maksimum yanÄ±t uzunluÄŸu
            temperature (Optional[float], optional): SÄ±caklÄ±k parametresi
            top_p (float, optional): Top-p Ã¶rnekleme parametresi
            do_sample (bool, optional): Ã–rnekleme yapÄ±lsÄ±n mÄ±
            use_history (bool, optional): Sohbet geÃ§miÅŸi kullanÄ±lsÄ±n mÄ±
            
        Returns:
            Tuple[str, List[str]]: YanÄ±t ve kullanÄ±lan kaynaklar
        """
        # Konu dÄ±ÅŸÄ± soru kontrolÃ¼ yap
        if not self._is_relevant_query(query):
            return "ÃœzgÃ¼nÃ¼m, bu konu hakkÄ±nda bilgim yok. Ben kadÄ±na yÃ¶nelik ÅŸiddet, yasal haklar ve psikolojik destek konularÄ±nda yardÄ±mcÄ± olabilirim.", []
        try:
            # SÄ±ÄŸÄ±nma evleri veya danÄ±ÅŸma merkezleri hakkÄ±nda soru sorulup sorulmadÄ±ÄŸÄ±nÄ± kontrol et
            shelter_keywords = [
                "sÄ±ÄŸÄ±nma", "sÄ±ÄŸÄ±nak", "sÄ±ÄŸÄ±nmaevi", "konukevi", "kadÄ±n sÄ±ÄŸÄ±nmaevi", 
                "sÄ±ÄŸÄ±nabileceÄŸim", "sÄ±ÄŸÄ±nabilir miyim", "nereye gidebilirim", "nerede kalabilirim",
                "ÅŸÃ¶nim", "koruma", "barÄ±nma", "kadÄ±n konukevi", "gidebileceÄŸim yer", "barÄ±nma kuruluÅŸlarÄ±"
            ]
            
            counseling_keywords = [
                "danÄ±ÅŸma", "destek", "merkez", "danÄ±ÅŸma merkezi", "kadÄ±n danÄ±ÅŸma", 
                "danÄ±ÅŸabileceÄŸim", "yardÄ±m alabileceÄŸim", "baÅŸvurabileceÄŸim", "destek hattÄ±",
                "danÄ±ÅŸmanlÄ±k", "mor Ã§atÄ±", "kadÄ±n dayanÄ±ÅŸma", "kadav"
            ]
            
            # Åehir isimlerini kontrol et
            city = self._find_city_in_query(query)
            
            # Åehir kontrolÃ¼
            city_mentioned = None
            if hasattr(self, 'siginma_evleri') and self.siginma_evleri:
                for shelter in self.siginma_evleri:
                    city = shelter.get("city", "").lower()
                    if city in query.lower():
                        city_mentioned = city
                        break
            
            # Sorgu tÃ¼rÃ¼ kontrolÃ¼
            is_shelter_query = any(keyword in query.lower() for keyword in self.SHELTER_KEYWORDS)
            is_counseling_query = any(keyword in query.lower() for keyword in self.COUNSELING_KEYWORDS)
            
            # BaÄŸlam hazÄ±rlama
            if context is None:
                context = self.get_context(query)
            
            context_text = ""
            sources = []
            
            # SÄ±ÄŸÄ±nma evi veya danÄ±ÅŸma merkezi sorgusu iÅŸleme
            if (is_shelter_query or is_counseling_query) and hasattr(self, 'siginma_evleri'):
                shelter_info = ""
                counseling_info = ""
                
                # Åehre Ã¶zel bilgiler
                if city_mentioned:
                    # SÄ±ÄŸÄ±nma evi bilgileri
                    shelter = next(
                        (s for s in self.siginma_evleri 
                         if self._normalize_city(s.get("city", "")) == self._normalize_city(city_mentioned)),
                        None
                    )
                    
                    if shelter:
                        shelter_info = f"**{shelter.get('city')} ÅÃ–NÄ°M:**\n"
                        shelter_info += self._format_contact_info(shelter)
                        sources.append("siginma_evleri.json")
                    
                    # DanÄ±ÅŸma merkezi bilgileri
                    if hasattr(self, 'danisma_merkezleri'):
                        city_centers = [
                            c for c in self.danisma_merkezleri
                            if self._normalize_city(c.get("city", "")) == self._normalize_city(city_mentioned)
                        ]
                        
                        if city_centers:
                            counseling_info = f"**{city_mentioned.title()} Åehrindeki KadÄ±n DanÄ±ÅŸma Merkezleri:**\n\n"
                            for center in sorted(city_centers, 
                                               key=lambda x: x.get('type', '') != 'BaÄŸÄ±msÄ±z')[:3]:
                                counseling_info += f"**{center.get('name')}**\n"
                                counseling_info += f"TÃ¼rÃ¼: {center.get('type', 'BelirtilmemiÅŸ')}\n"
                                counseling_info += self._format_contact_info(center)
                                counseling_info += f"Telefon: {', '.join(center.get('phone', []))}\n"
                                counseling_info += f"Adres: {center.get('address')}\n"
                                if center.get('website'):
                                    counseling_info += f"Web: {center.get('website')}\n"
                                counseling_info += "\n"
                            sources.append("kadin_danisma_merkezleri.json")
                else:
                    # Åehir belirtilmemiÅŸse Ã¶nemli merkezleri gÃ¶ster
                    # Ã–nemli ÅŸehirlerdeki sÄ±ÄŸÄ±nma evlerini ekle
                    big_cities = ["istanbul", "ankara", "izmir", "bursa", "antalya"]
                    shelter_info += "**Ã–nemli Åehirlerdeki ÅÃ–NÄ°M Bilgileri:**\n\n"
                    for city_name in big_cities:
                        for shelter in self.siginma_evleri:
                            if shelter.get("city", "").lower() == city_name:
                                shelter_info += f"**{shelter.get('city')} ÅÃ–NÄ°M:**\n"
                                shelter_info += f"Telefon: {', '.join(shelter.get('phone', []))}\n"
                                shelter_info += f"Adres: {shelter.get('address')}\n\n"
                                break
                    sources.append("siginma_evleri.json")
                    
                    # BaÄŸÄ±msÄ±z kadÄ±n Ã¶rgÃ¼tlerini ekle
                    if hasattr(self, 'danisma_merkezleri') and self.danisma_merkezleri:
                        counseling_info += "**BaÄŸÄ±msÄ±z KadÄ±n Ã–rgÃ¼tleri:**\n\n"
                        for center in self.danisma_merkezleri:
                            if center.get("type") == "BaÄŸÄ±msÄ±z":
                                counseling_info += f"**{center.get('name')}:**\n"
                                counseling_info += f"Telefon: {', '.join(center.get('phone', []))}\n"
                                counseling_info += f"Adres: {center.get('address')}\n"
                                if center.get('website'):
                                    counseling_info += f"Web: {center.get('website')}\n"
                                counseling_info += "\n"
                                if len(counseling_info.split('\n')) > 15:  # En fazla 3 merkez gÃ¶ster
                                    break
                        sources.append("kadin_danisma_merkezleri.json")
                
                # Acil yardÄ±m hatlarÄ±nÄ± ekle
                emergency_info = "\n**Acil YardÄ±m HatlarÄ±:**\n"
                emergency_info += "- Alo 183 Sosyal Destek HattÄ±\n"
                emergency_info += "- 155 Polis Ä°mdat\n"
                emergency_info += "- 156 Jandarma\n"
                emergency_info += "- 112 Acil YardÄ±m\n"
                
                # JSON verilerini baÄŸlam metnine ekle
                if shelter_info:
                    context_text += shelter_info + "\n\n"
                if counseling_info:
                    context_text += counseling_info + "\n\n"
                context_text += emergency_info + "\n\n"
                
                # Web kaynaklarÄ±nÄ± ekle
                context_text += "Web kaynaklarÄ±ndan elde edilen ek bilgiler:\n\n"
            
            # Web kaynaklarÄ±ndan bilgileri ekle
            for doc in context:
                context_text += doc.page_content + "\n\n"
                source = doc.metadata.get("source", "")
                
                # Kaynak bilgisini dÃ¼zenle
                if source and source not in sources:
                    # PDF dosya yolunu iÅŸle
                    if ".pdf" in source.lower():
                        # Sadece dosya adÄ±nÄ± al
                        pdf_name = source.split('/')[-1].split('\\')[-1]
                        if pdf_name not in sources:
                            sources.append(pdf_name)
                    # Web URL'leri ve diÄŸer kaynaklar
                    elif "http" in source.lower() or "www." in source.lower():
                        # Web URL'lerini doÄŸrudan ekle
                        if source not in sources:
                            sources.append(source)
                    # DiÄŸer kaynaklar
                    else:
                        sources.append(source)
                    
            # Sohbet geÃ§miÅŸi
            conversation_context = ""
            if use_history and self.conversation_history:
                conversation_context = self.get_conversation_context()
                
            # OpenAI ile yanÄ±t oluÅŸtur
            try:
                # OpenAI API anahtarÄ± yoksa uygun bir mesaj dÃ¶ndÃ¼r
                if not self.openai_api_key or not self.llm:
                    self.logger.warning("OpenAI API anahtarÄ± bulunamadÄ±ÄŸÄ± iÃ§in yanÄ±t Ã¼retilemiyor.")
                    return (
                        "ÃœzgÃ¼nÃ¼m, ÅŸu anda OpenAI API anahtarÄ± bulunamadÄ±ÄŸÄ± iÃ§in sorularÄ±nÄ±zÄ± yanÄ±tlayamÄ±yorum. "
                        "LÃ¼tfen .env dosyasÄ±na geÃ§erli bir OpenAI API anahtarÄ± ekleyin."
                    ), []
                
                # Sistem mesajÄ±nÄ± _get_system_message fonksiyonundan al
                system_message = self._get_system_message()
                
                user_message = f"BaÄŸlam:\n{context_text}\n"
                
                # Sohbet geÃ§miÅŸini ekle
                if conversation_context:
                    user_message += f"\n{conversation_context}"
                    
                user_message += f"\n\nSoru: {query}"
                
                # OpenAI API ile yanÄ±t oluÅŸtur
                messages = [
                    system_message,
                    {"role": "user", "content": user_message}
                ]
                
                # Benzer soru kontrolÃ¼ yap ve Ã§eÅŸitlilik saÄŸla
                try:
                    is_similar, similar_question = self._is_similar_question(query)
                except Exception as e:
                    self.logger.error(f"Benzer soru kontrolÃ¼ yapÄ±lÄ±rken hata: {str(e)}")
                    is_similar, similar_question = False, ""
                
                # SÄ±caklÄ±k deÄŸerini ayarla
                actual_temperature = temperature if temperature is not None else self.temperature
                
                # Benzer soru iÃ§in Ã§eÅŸitlilik saÄŸla
                if is_similar:
                    # SÄ±caklÄ±k deÄŸerini artÄ±r (daha Ã§eÅŸitli yanÄ±tlar iÃ§in)
                    actual_temperature = min(actual_temperature + 0.2, 1.0)  # Max 1.0 olacak ÅŸekilde artÄ±r
                    # Top_p deÄŸerini artÄ±r (daha geniÅŸ kelime daÄŸÄ±lÄ±mÄ± iÃ§in)
                    actual_top_p = 0.98
                    self.logger.info(f"Benzer soru iÃ§in Ã§eÅŸitlilik parametreleri: temperature={actual_temperature}, top_p={actual_top_p}")
                else:
                    actual_top_p = top_p
                
                # Daha kapsamlÄ± yanÄ±tlar iÃ§in parametreleri ayarla
                response = self.llm.invoke(
                    messages,
                    temperature=actual_temperature,  # Ã‡eÅŸitlilik iÃ§in ayarlanmÄ±ÅŸ sÄ±caklÄ±k
                    max_tokens=2048,  # Daha uzun yanÄ±tlar iÃ§in
                    top_p=actual_top_p,  # Ã‡eÅŸitlilik iÃ§in ayarlanmÄ±ÅŸ top_p
                )
                answer = response.content
                
                self.logger.info("OpenAI ile yanÄ±t baÅŸarÄ±yla oluÅŸturuldu")
                
                # EÄŸer yanÄ±t "bilgim yok" iÃ§eriyorsa boÅŸ kaynak listesi dÃ¶ndÃ¼r
                if "ÃœzgÃ¼nÃ¼m, bu konuda bilgim yok" in answer or "bilgim bulunmamaktadÄ±r" in answer.lower():
                    return answer, []
                    
                return answer, sources
            except Exception as e:
                self.logger.error(f"OpenAI ile yanÄ±t oluÅŸturulurken hata: {str(e)}")
                return f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}", []
                
        except Exception as e:
            self.logger.error(f"YanÄ±t oluÅŸturulurken hata: {str(e)}")
            return "ÃœzgÃ¼nÃ¼m, yanÄ±t oluÅŸturulurken bir hata meydana geldi.", []
            
    def retrieve_context(self, query: str, k: int = 5) -> List[Document]:
        """Sorgu iÃ§in vektÃ¶r veritabanÄ±ndan baÄŸlam dÃ¶kÃ¼manlarÄ± alÄ±r"""
        if not self.vector_store:
            self.logger.warning("VektÃ¶r veritabanÄ± yÃ¼klenmedi: BaÄŸlam alÄ±namÄ±yor")
            return []
        try:
            self.logger.info(f"Sorgu iÃ§in baÄŸlam alÄ±nÄ±yor: {query}")
            
            # VektÃ¶r veritabanÄ± hakkÄ±nda bilgi al
            if hasattr(self.vector_store, "_collection") and hasattr(self.vector_store._collection, "count"):
                count = self.vector_store._collection.count()
                self.logger.info(f"VektÃ¶r veritabanÄ±nda {count} dÃ¶kÃ¼man bulunuyor")
                
                # EÄŸer dÃ¶kÃ¼man yoksa uyarÄ± ver
                if count == 0:
                    self.logger.warning("VektÃ¶r veritabanÄ±nda hiÃ§ dÃ¶kÃ¼man bulunmuyor. LÃ¼tfen prepare_data.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak vektÃ¶r veritabanÄ±nÄ± oluÅŸturun.")
                    return []
            
            # Benzerlik aramasÄ± yap
            results = self.vector_store.similarity_search(query, k=k)
            self.logger.info(f"{len(results)} baÄŸlam dÃ¶kÃ¼manÄ± bulundu")
            
            # Bulunan dÃ¶kÃ¼manlarÄ± logla
            if results:
                for i, doc in enumerate(results):
                    source = doc.metadata.get("source", "Bilinmeyen kaynak")
                    self.logger.info(f"DÃ¶kÃ¼man {i+1}: {source} - {len(doc.page_content)} karakter")
            else:
                self.logger.warning(f"Sorgu iÃ§in hiÃ§ dÃ¶kÃ¼man bulunamadÄ±: {query}")
                
            return results
        except Exception as e:
            self.logger.error(f"BaÄŸlam alÄ±nÄ±rken hata: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())
            return []
            
    def _load_shelter_data(self):
        """SÄ±ÄŸÄ±nma evleri ve danÄ±ÅŸma merkezleri verilerini yÃ¼kle"""
        try:
            # Proje dizinini al
            project_dir = Path(__file__).resolve().parent
            data_dir = project_dir / "data"
            
            # SÄ±ÄŸÄ±nma evleri JSON dosyasÄ±nÄ± yÃ¼kle
            siginma_evleri_path = data_dir / "siginma_evleri.json"
            if siginma_evleri_path.exists():
                with open(siginma_evleri_path, "r", encoding="utf-8") as f:
                    self.siginma_evleri = json.load(f)
                self.logger.info(f"{len(self.siginma_evleri)} adet sÄ±ÄŸÄ±nma evi bilgisi yÃ¼klendi")
            else:
                self.logger.warning(f"SÄ±ÄŸÄ±nma evleri dosyasÄ± bulunamadÄ±: {siginma_evleri_path}")
            
            # KadÄ±n danÄ±ÅŸma merkezleri JSON dosyasÄ±nÄ± yÃ¼kle
            danisma_merkezleri_path = data_dir / "kadin_danisma_merkezleri.json"
            if danisma_merkezleri_path.exists():
                with open(danisma_merkezleri_path, "r", encoding="utf-8") as f:
                    danisma_data = json.load(f)
                    
                    # JSON formatÄ±nÄ± kontrol et ve uygun ÅŸekilde iÅŸle
                    if isinstance(danisma_data, list):
                        # Dizi formatÄ± - doÄŸrudan kullan
                        self.danisma_merkezleri = danisma_data
                        self.logger.info(f"{len(self.danisma_merkezleri)} adet kadÄ±n danÄ±ÅŸma merkezi bilgisi yÃ¼klendi")
                    elif isinstance(danisma_data, dict):
                        # Åehir bazlÄ± nesne formatÄ± - dÃ¼z listeye dÃ¶nÃ¼ÅŸtÃ¼r
                        flat_list = []
                        for city, centers in danisma_data.items():
                            for center in centers:
                                # Åehir bilgisini ekle
                                if "city" not in center:
                                    center["city"] = city
                                flat_list.append(center)
                        self.danisma_merkezleri = flat_list
                        self.logger.info(f"{len(self.danisma_merkezleri)} adet kadÄ±n danÄ±ÅŸma merkezi bilgisi yÃ¼klendi (ÅŸehir bazlÄ± format)")
                    else:
                        self.logger.warning("KadÄ±n danÄ±ÅŸma merkezleri JSON formatÄ± tanÄ±nmadÄ±")
                        self.danisma_merkezleri = []
            else:
                self.logger.warning(f"KadÄ±n danÄ±ÅŸma merkezleri dosyasÄ± bulunamadÄ±: {danisma_merkezleri_path}")
                self.danisma_merkezleri = []
                
        except Exception as e:
            self.logger.error(f"SÄ±ÄŸÄ±nma evleri ve danÄ±ÅŸma merkezleri verilerini yÃ¼klerken hata: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())
    
    def _calculate_similarity(self, query1: str, query2: str) -> float:
        """Ä°ki sorgu arasÄ±ndaki benzerliÄŸi hesaplar (0-1 arasÄ±)"""
        try:
            # SorgularÄ± normalize et
            import re
            import string
            from difflib import SequenceMatcher
            
            normalized_query1 = self._normalize_text(query1)
            normalized_query2 = self._normalize_text(query2)
            
            # Basit benzerlik hesaplama (0-1 arasÄ±)
            similarity = SequenceMatcher(None, normalized_query1, normalized_query2).ratio()
            return similarity
        except Exception as e:
            self.logger.error(f"Benzerlik hesaplanÄ±rken hata: {str(e)}")
            return 0.0
    
    def _normalize_text(self, text: str) -> str:
        """Metni normalize eder (kÃ¼Ã§Ã¼k harf ve noktalama iÅŸaretlerini kaldÄ±rma)"""
        import re
        import string
        # TÃ¼rkÃ§e karakterleri koru ama noktalama iÅŸaretlerini kaldÄ±r
        text = text.lower()
        text = re.sub(r'[' + string.punctuation + ']', '', text)
        return text
        
    def _is_similar_question(self, query: str, threshold: float = 0.8) -> Tuple[bool, str]:
        """Verilen sorgunun daha Ã¶nce sorulmuÅŸ sorulara benzer olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
        if not self.question_history:
            return False, ""
        
        # En yÃ¼ksek benzerliÄŸi ve ilgili soruyu bul
        max_similarity = 0.0
        most_similar_question = ""
        
        for prev_query in self.question_history:
            similarity = self._calculate_similarity(query, prev_query)
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_question = prev_query
        
        # Benzerlik eÅŸiÄŸini aÅŸÄ±yorsa, benzer soru olarak kabul et
        if max_similarity >= threshold:
            self.logger.info(f"Benzer soru tespit edildi: {most_similar_question} (benzerlik: {max_similarity:.2f})")
            return True, most_similar_question
        
        return False, ""
        
    def _is_relevant_query(self, query: str) -> bool:
        """Sorgunun chatbot'un konusu ile ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
        # Konu ile ilgili anahtar kelimeler
        relevant_keywords = [
            # KadÄ±na yÃ¶nelik ÅŸiddet ile ilgili kelimeler
            "ÅŸiddet", "taciz", "tecavÃ¼z", "istismar", "darp", "dayak", "tehdit", "takip", 
            "kadÄ±n", "kadÄ±na", "kadÄ±na ÅŸiddet", "aile iÃ§i ÅŸiddet", "ev iÃ§i ÅŸiddet", "fiziksel ÅŸiddet", 
            "psikolojik ÅŸiddet", "cinsel ÅŸiddet", "ekonomik ÅŸiddet", "dijital ÅŸiddet", "Ä±srarlÄ± takip",
            # Yasal haklar ile ilgili kelimeler
            "hak", "yasal", "kanun", "hukuk", "dava", "ÅŸikayet", "boÅŸanma", "nafaka", "velayet", 
            "uzaklaÅŸtÄ±rma", "koruma", "tedbir", "6284", "istanbul sÃ¶zleÅŸmesi", "cedaw", 
            # Psikolojik destek ile ilgili kelimeler
            "destek", "psikolojik", "terapi", "travma", "danÄ±ÅŸma", "yardÄ±m", "tedavi", "iyileÅŸme",
            "tssb", "depresyon", "anksiyete", "panik", "korku", "gÃ¼venlik", "gÃ¼venli",
            # SÄ±ÄŸÄ±nma ve destek merkezleri ile ilgili kelimeler
            "sÄ±ÄŸÄ±nma", "sÄ±ÄŸÄ±nak", "ÅŸÃ¶nim", "merkez", "danÄ±ÅŸma merkezi", "mor Ã§atÄ±", "kadÄ±n dayanÄ±ÅŸma",
            "kadav", "acil", "telefon", "hat", "183", "155", "156", "112",
            # Åiddet uygulayan kiÅŸiler iÃ§in eklenen kelimeler
            "Ã¶fke", "kontrol", "saldÄ±rganlÄ±k", "dÃ¶vÃ¼yorum", "vuruyorum", "zarar veriyorum", 
            "ÅŸiddet uyguluyorum", "kendimi tutamÄ±yorum", "Ã¶fke kontrolÃ¼", "agresif", "sinirliyim",
            "piÅŸmanlÄ±k", "kendimi kontrol edemiyorum", "kendime zarar", "intihar", "zarar vermek",
            "tedavi olmak", "yardÄ±m almak", "terapist", "psikiyatrist", "psikolog"
        ]
        
        # Sorgu metni iÃ§inde ilgili anahtar kelimelerden herhangi biri var mÄ± kontrol et
        normalized_query = self._normalize_text(query.lower())
        for keyword in relevant_keywords:
            if keyword.lower() in normalized_query:
                return True
                
        # Åiddet uygulama veya kendine zarar verme iÃ§eren sorgular iÃ§in Ã¶zel kontrol
        violence_patterns = [
            "dÃ¶vÃ¼yorum", "vuruyorum", "ÅŸiddet uyguluyorum", "zarar veriyorum", "kendimi tutamÄ±yorum",
            "kendime zarar", "intihar", "Ã¶ldÃ¼rmek", "zarar vermek", "kendimi kontrol edemiyorum"
        ]
        
        for pattern in violence_patterns:
            if pattern in normalized_query:
                return True
                
        # VektÃ¶r veritabanÄ±ndan ilgili dokÃ¼manlar var mÄ± kontrol et
        try:
            if self.vector_store:
                docs = self.vector_store.similarity_search(query, k=3)
                if docs and len(docs) > 0:
                    # Benzerlik skoru yeterince yÃ¼ksek mi kontrol et
                    similarity_scores = [doc.metadata.get("score", 0) for doc in docs if "score" in doc.metadata]
                    if similarity_scores and max(similarity_scores, default=0) > 0.7:
                        return True
        except Exception as e:
            self.logger.error(f"VektÃ¶r veritabanÄ± sorgusu sÄ±rasÄ±nda hata: {str(e)}")
            
        # HiÃ§bir ilgili anahtar kelime veya benzer dokÃ¼man bulunamadÄ±ysa konu dÄ±ÅŸÄ± kabul et
        return False
    
    def reset_chat(self):
        """Sohbet geÃ§miÅŸini sÄ±fÄ±rla"""
        self.conversation_history = []
        self.question_history = []
        self.used_sources = {}
        self.logger.info("Sohbet geÃ§miÅŸini sÄ±fÄ±rladÄ±m")
